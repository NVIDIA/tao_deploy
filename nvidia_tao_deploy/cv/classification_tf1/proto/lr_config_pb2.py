# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: nvidia_tao_deploy/cv/classification_tf1/proto/lr_config.proto
"""Generated protocol buffer code."""
from google.protobuf.internal import builder as _builder
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n=nvidia_tao_deploy/cv/classification_tf1/proto/lr_config.proto\"G\n\x0cStepLrConfig\x12\x15\n\rlearning_rate\x18\x01 \x01(\x02\x12\x11\n\tstep_size\x18\x02 \x01(\r\x12\r\n\x05gamma\x18\x03 \x01(\x02\"t\n\x12SoftAnnealLrConfig\x12\x15\n\rlearning_rate\x18\x01 \x01(\x02\x12\x12\n\nsoft_start\x18\x02 \x01(\x02\x12\x19\n\x11\x61nnealing_divider\x18\x03 \x01(\x02\x12\x18\n\x10\x61nnealing_points\x18\x07 \x03(\x02\"Q\n\x0e\x43osineLrConfig\x12\x15\n\rlearning_rate\x18\x01 \x01(\x02\x12\x14\n\x0cmin_lr_ratio\x18\x02 \x01(\x02\x12\x12\n\nsoft_start\x18\x03 \x01(\x02\"\x88\x01\n\x08LRConfig\x12\x1d\n\x04step\x18\x01 \x01(\x0b\x32\r.StepLrConfigH\x00\x12*\n\x0bsoft_anneal\x18\x02 \x01(\x0b\x32\x13.SoftAnnealLrConfigH\x00\x12!\n\x06\x63osine\x18\x03 \x01(\x0b\x32\x0f.CosineLrConfigH\x00\x42\x0e\n\x0clr_schedulerb\x06proto3')

_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'nvidia_tao_deploy.cv.classification_tf1.proto.lr_config_pb2', globals())
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  _STEPLRCONFIG._serialized_start=65
  _STEPLRCONFIG._serialized_end=136
  _SOFTANNEALLRCONFIG._serialized_start=138
  _SOFTANNEALLRCONFIG._serialized_end=254
  _COSINELRCONFIG._serialized_start=256
  _COSINELRCONFIG._serialized_end=337
  _LRCONFIG._serialized_start=340
  _LRCONFIG._serialized_end=476
# @@protoc_insertion_point(module_scope)
