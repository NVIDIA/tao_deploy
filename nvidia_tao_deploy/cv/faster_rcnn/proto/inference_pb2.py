# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: nvidia_tao_deploy/cv/faster_rcnn/proto/inference.proto
"""Generated protocol buffer code."""
from google.protobuf.internal import builder as _builder
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from nvidia_tao_deploy.cv.faster_rcnn.proto import trt_config_pb2 as nvidia__tao__deploy_dot_cv_dot_faster__rcnn_dot_proto_dot_trt__config__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n6nvidia_tao_deploy/cv/faster_rcnn/proto/inference.proto\x1a\x37nvidia_tao_deploy/cv/faster_rcnn/proto/trt_config.proto\"\xc4\x03\n\x0fInferenceConfig\x12\x12\n\nimages_dir\x18\x01 \x01(\t\x12\r\n\x05model\x18\x02 \x01(\t\x12\x12\n\nbatch_size\x18\x0f \x01(\r\x12\x19\n\x11rpn_pre_nms_top_N\x18\n \x01(\r\x12\x19\n\x11rpn_nms_max_boxes\x18\x07 \x01(\r\x12!\n\x19rpn_nms_overlap_threshold\x18\x08 \x01(\x02\x12 \n\x18\x62\x62ox_visualize_threshold\x18\x05 \x01(\x02\x12\x1f\n\x17object_confidence_thres\x18\x10 \x01(\x02\x12 \n\x18\x63lassifier_nms_max_boxes\x18\t \x01(\r\x12(\n classifier_nms_overlap_threshold\x18\x06 \x01(\x02\x12\"\n\x1a\x64\x65tection_image_output_dir\x18\x0b \x01(\t\x12\x17\n\x0f\x62\x62ox_caption_on\x18\x0c \x01(\x08\x12\x17\n\x0flabels_dump_dir\x18\r \x01(\t\x12$\n\rtrt_inference\x18\x0e \x01(\x0b\x32\r.TrtInference\x12\x16\n\x0enms_score_bits\x18\x11 \x01(\rb\x06proto3')

_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'nvidia_tao_deploy.cv.faster_rcnn.proto.inference_pb2', globals())
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  _INFERENCECONFIG._serialized_start=116
  _INFERENCECONFIG._serialized_end=568
# @@protoc_insertion_point(module_scope)
