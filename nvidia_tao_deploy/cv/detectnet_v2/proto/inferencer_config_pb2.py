# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: nvidia_tao_deploy/cv/detectnet_v2/proto/inferencer_config.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor.FileDescriptor(
  name='nvidia_tao_deploy/cv/detectnet_v2/proto/inferencer_config.proto',
  package='',
  syntax='proto3',
  serialized_options=None,
  serialized_pb=_b('\n?nvidia_tao_deploy/cv/detectnet_v2/proto/inferencer_config.proto\"`\n\x10\x43\x61libratorConfig\x12\x19\n\x11\x63\x61libration_cache\x18\x01 \x01(\t\x12\x1e\n\x16\x63\x61libration_tensorfile\x18\x02 \x01(\t\x12\x11\n\tn_batches\x18\x03 \x01(\x05\"\x1a\n\tTLTConfig\x12\r\n\x05model\x18\x01 \x01(\t\"\xf1\x02\n\x0eTensorRTConfig\x12&\n\x06parser\x18\x01 \x01(\x0e\x32\x16.TensorRTConfig.Parser\x12\x12\n\ncaffemodel\x18\x02 \x01(\t\x12\x10\n\x08prototxt\x18\x03 \x01(\t\x12\x11\n\tuff_model\x18\x04 \x01(\t\x12\x12\n\netlt_model\x18\x05 \x01(\t\x12:\n\x11\x62\x61\x63kend_data_type\x18\x06 \x01(\x0e\x32\x1f.TensorRTConfig.BackendDataType\x12\x13\n\x0bsave_engine\x18\x07 \x01(\x08\x12\x12\n\ntrt_engine\x18\x08 \x01(\t\x12,\n\x11\x63\x61librator_config\x18\t \x01(\x0b\x32\x11.CalibratorConfig\"&\n\x06Parser\x12\t\n\x05\x43\x41\x46\x46\x45\x10\x00\x12\x07\n\x03UFF\x10\x01\x12\x08\n\x04\x45TLT\x10\x02\"/\n\x0f\x42\x61\x63kendDataType\x12\x08\n\x04\x46P32\x10\x00\x12\x08\n\x04\x46P16\x10\x01\x12\x08\n\x04INT8\x10\x02\"\xb2\x02\n\x10InferencerConfig\x12 \n\ntlt_config\x18\x01 \x01(\x0b\x32\n.TLTConfigH\x00\x12*\n\x0ftensorrt_config\x18\x02 \x01(\x0b\x32\x0f.TensorRTConfigH\x00\x12\x13\n\x0binput_nodes\x18\x03 \x03(\t\x12\x14\n\x0coutput_nodes\x18\x04 \x03(\t\x12\x12\n\nbatch_size\x18\x05 \x01(\x05\x12\x14\n\x0cimage_height\x18\x06 \x01(\x05\x12\x13\n\x0bimage_width\x18\x07 \x01(\x05\x12\x16\n\x0eimage_channels\x18\x08 \x01(\x05\x12\x11\n\tgpu_index\x18\t \x01(\x05\x12\x16\n\x0etarget_classes\x18\n \x03(\t\x12\x0e\n\x06stride\x18\x0b \x01(\x05\x42\x13\n\x11model_config_typeb\x06proto3')
)



_TENSORRTCONFIG_PARSER = _descriptor.EnumDescriptor(
  name='Parser',
  full_name='TensorRTConfig.Parser',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='CAFFE', index=0, number=0,
      serialized_options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='UFF', index=1, number=1,
      serialized_options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='ETLT', index=2, number=2,
      serialized_options=None,
      type=None),
  ],
  containing_type=None,
  serialized_options=None,
  serialized_start=476,
  serialized_end=514,
)
_sym_db.RegisterEnumDescriptor(_TENSORRTCONFIG_PARSER)

_TENSORRTCONFIG_BACKENDDATATYPE = _descriptor.EnumDescriptor(
  name='BackendDataType',
  full_name='TensorRTConfig.BackendDataType',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='FP32', index=0, number=0,
      serialized_options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='FP16', index=1, number=1,
      serialized_options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='INT8', index=2, number=2,
      serialized_options=None,
      type=None),
  ],
  containing_type=None,
  serialized_options=None,
  serialized_start=516,
  serialized_end=563,
)
_sym_db.RegisterEnumDescriptor(_TENSORRTCONFIG_BACKENDDATATYPE)


_CALIBRATORCONFIG = _descriptor.Descriptor(
  name='CalibratorConfig',
  full_name='CalibratorConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='calibration_cache', full_name='CalibratorConfig.calibration_cache', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='calibration_tensorfile', full_name='CalibratorConfig.calibration_tensorfile', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='n_batches', full_name='CalibratorConfig.n_batches', index=2,
      number=3, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=67,
  serialized_end=163,
)


_TLTCONFIG = _descriptor.Descriptor(
  name='TLTConfig',
  full_name='TLTConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='model', full_name='TLTConfig.model', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=165,
  serialized_end=191,
)


_TENSORRTCONFIG = _descriptor.Descriptor(
  name='TensorRTConfig',
  full_name='TensorRTConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='parser', full_name='TensorRTConfig.parser', index=0,
      number=1, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='caffemodel', full_name='TensorRTConfig.caffemodel', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='prototxt', full_name='TensorRTConfig.prototxt', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='uff_model', full_name='TensorRTConfig.uff_model', index=3,
      number=4, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='etlt_model', full_name='TensorRTConfig.etlt_model', index=4,
      number=5, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='backend_data_type', full_name='TensorRTConfig.backend_data_type', index=5,
      number=6, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='save_engine', full_name='TensorRTConfig.save_engine', index=6,
      number=7, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='trt_engine', full_name='TensorRTConfig.trt_engine', index=7,
      number=8, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='calibrator_config', full_name='TensorRTConfig.calibrator_config', index=8,
      number=9, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _TENSORRTCONFIG_PARSER,
    _TENSORRTCONFIG_BACKENDDATATYPE,
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=194,
  serialized_end=563,
)


_INFERENCERCONFIG = _descriptor.Descriptor(
  name='InferencerConfig',
  full_name='InferencerConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='tlt_config', full_name='InferencerConfig.tlt_config', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='tensorrt_config', full_name='InferencerConfig.tensorrt_config', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='input_nodes', full_name='InferencerConfig.input_nodes', index=2,
      number=3, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='output_nodes', full_name='InferencerConfig.output_nodes', index=3,
      number=4, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='batch_size', full_name='InferencerConfig.batch_size', index=4,
      number=5, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='image_height', full_name='InferencerConfig.image_height', index=5,
      number=6, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='image_width', full_name='InferencerConfig.image_width', index=6,
      number=7, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='image_channels', full_name='InferencerConfig.image_channels', index=7,
      number=8, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='gpu_index', full_name='InferencerConfig.gpu_index', index=8,
      number=9, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='target_classes', full_name='InferencerConfig.target_classes', index=9,
      number=10, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='stride', full_name='InferencerConfig.stride', index=10,
      number=11, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='model_config_type', full_name='InferencerConfig.model_config_type',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=566,
  serialized_end=872,
)

_TENSORRTCONFIG.fields_by_name['parser'].enum_type = _TENSORRTCONFIG_PARSER
_TENSORRTCONFIG.fields_by_name['backend_data_type'].enum_type = _TENSORRTCONFIG_BACKENDDATATYPE
_TENSORRTCONFIG.fields_by_name['calibrator_config'].message_type = _CALIBRATORCONFIG
_TENSORRTCONFIG_PARSER.containing_type = _TENSORRTCONFIG
_TENSORRTCONFIG_BACKENDDATATYPE.containing_type = _TENSORRTCONFIG
_INFERENCERCONFIG.fields_by_name['tlt_config'].message_type = _TLTCONFIG
_INFERENCERCONFIG.fields_by_name['tensorrt_config'].message_type = _TENSORRTCONFIG
_INFERENCERCONFIG.oneofs_by_name['model_config_type'].fields.append(
  _INFERENCERCONFIG.fields_by_name['tlt_config'])
_INFERENCERCONFIG.fields_by_name['tlt_config'].containing_oneof = _INFERENCERCONFIG.oneofs_by_name['model_config_type']
_INFERENCERCONFIG.oneofs_by_name['model_config_type'].fields.append(
  _INFERENCERCONFIG.fields_by_name['tensorrt_config'])
_INFERENCERCONFIG.fields_by_name['tensorrt_config'].containing_oneof = _INFERENCERCONFIG.oneofs_by_name['model_config_type']
DESCRIPTOR.message_types_by_name['CalibratorConfig'] = _CALIBRATORCONFIG
DESCRIPTOR.message_types_by_name['TLTConfig'] = _TLTCONFIG
DESCRIPTOR.message_types_by_name['TensorRTConfig'] = _TENSORRTCONFIG
DESCRIPTOR.message_types_by_name['InferencerConfig'] = _INFERENCERCONFIG
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

CalibratorConfig = _reflection.GeneratedProtocolMessageType('CalibratorConfig', (_message.Message,), dict(
  DESCRIPTOR = _CALIBRATORCONFIG,
  __module__ = 'nvidia_tao_deploy.cv.detectnet_v2.proto.inferencer_config_pb2'
  # @@protoc_insertion_point(class_scope:CalibratorConfig)
  ))
_sym_db.RegisterMessage(CalibratorConfig)

TLTConfig = _reflection.GeneratedProtocolMessageType('TLTConfig', (_message.Message,), dict(
  DESCRIPTOR = _TLTCONFIG,
  __module__ = 'nvidia_tao_deploy.cv.detectnet_v2.proto.inferencer_config_pb2'
  # @@protoc_insertion_point(class_scope:TLTConfig)
  ))
_sym_db.RegisterMessage(TLTConfig)

TensorRTConfig = _reflection.GeneratedProtocolMessageType('TensorRTConfig', (_message.Message,), dict(
  DESCRIPTOR = _TENSORRTCONFIG,
  __module__ = 'nvidia_tao_deploy.cv.detectnet_v2.proto.inferencer_config_pb2'
  # @@protoc_insertion_point(class_scope:TensorRTConfig)
  ))
_sym_db.RegisterMessage(TensorRTConfig)

InferencerConfig = _reflection.GeneratedProtocolMessageType('InferencerConfig', (_message.Message,), dict(
  DESCRIPTOR = _INFERENCERCONFIG,
  __module__ = 'nvidia_tao_deploy.cv.detectnet_v2.proto.inferencer_config_pb2'
  # @@protoc_insertion_point(class_scope:InferencerConfig)
  ))
_sym_db.RegisterMessage(InferencerConfig)


# @@protoc_insertion_point(module_scope)
